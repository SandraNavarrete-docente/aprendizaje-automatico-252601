{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üéì **Taller 4.7.1: Taller de M√©todos de Clustering Basados en Modelos Probabilisticos**\n"
      ],
      "metadata": {
        "id": "oXCqPTRZDOp2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OBJETIVOS DEL TALLER:\n",
        "En esta pr√°ctica vamos a ver c√≥mo funcionan los algoritmos de clustering basado en Modelos Probabil√≠sticos como GMM.\n",
        "\n",
        "Los objetivos espec√≠ficos son:\n",
        "\n",
        "* Introducir los fundamentos te√≥ricos de los m√©todos de agrupamiento probabil√≠sticos, en particular los Modelos de Mezclas Gaussianas (GMM), entendiendo c√≥mo modelan los datos como una combinaci√≥n de distribuciones normales multivariadas.\n",
        "\n",
        "* Comprender el algoritmo de optimizaci√≥n EM (Expectation-Maximization) utilizado para estimar los par√°metros del modelo (medias, covarianzas y pesos de cada componente)."
      ],
      "metadata": {
        "id": "7upSBFL6RCda"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîß **CONFIGURACI√ìN INICIAL**"
      ],
      "metadata": {
        "id": "s2z_GPdRH4HG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [8, 8]"
      ],
      "metadata": {
        "id": "i-Xg1lLJDUak"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìÅ **CARGAR LOS DATASETS Y GRAFICAR SUS DISTRIBUCIONES**"
      ],
      "metadata": {
        "id": "jbgcqhpSH9_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar dataset artificial\n",
        "def cargar_dataset(nombre_dataset):\n",
        "    try:\n",
        "        # Intentar cargar desde URL alternativa\n",
        "        data_file_url = \"https://raw.githubusercontent.com/SandraNavarrete-docente/aprendizaje-automatico-252601/main/04-MODELOS-NO-SUPERVISADOS/data/\"+nombre_dataset\n",
        "        D = np.array(pd.read_excel(data_file_url,header=0))\n",
        "        print(\"‚úÖ Dataset cargado desde URL GitHub\")\n",
        "        return D\n",
        "    except:\n",
        "        print(\"‚ùå No se pudo cargar el dataset\")\n",
        "        return None\n",
        "\n",
        "def cargar_dataset_csv(nombre_dataset):\n",
        "    try:\n",
        "        # Intentar cargar desde URL alternativa\n",
        "        data_file_url = \"https://raw.githubusercontent.com/SandraNavarrete-docente/aprendizaje-automatico-252601/main/04-MODELOS-NO-SUPERVISADOS/data/\"+nombre_dataset\n",
        "        D = np.array(pd.read_csv(data_file_url,header=0))\n",
        "        print(\"‚úÖ Dataset cargado desde URL GitHub\")\n",
        "        return D\n",
        "    except:\n",
        "        print(\"‚ùå No se pudo cargar el dataset\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "ejuHthB-Hydr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéØ **1:Cree el Algoritmo de Clustering GMM**"
      ],
      "metadata": {
        "id": "CuG_2IWbtLe4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El algoritmo EM tiene un √∫nico par√°metro: el n√∫mero de cl√∫steres (K). Una vez fijado este valor, el primer paso consiste en inicializar el modelo. Se eligen unos centros iniciales de manera aleatoria, unas matrices de covarianzas fijas y unos pesos iniciales para las diferentes componentes. Sin m√°s informaci√≥n, lo m√°s normal ser√≠a asignar a todas las componentes el mismo peso.\n"
      ],
      "metadata": {
        "id": "_xn6mv8m7F3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def asignar_cov_iniciales(K):\n",
        "  # Asignar unas matrices de covarianzas iniciales\n",
        "  sigmas = []\n",
        "  for k in np.arange(K):\n",
        "      sigmas.append( np.diag( 0.1 * np.ones( Dx.shape[1] ) ) )\n",
        "  x, y = np.mgrid[(np.min(Dx[:,0])-0.1):(np.max(Dx[:,0])+0.1):.01,\n",
        "                  (np.min(Dx[:,1])-0.1):(np.max(Dx[:,1])+0.1):.01]\n",
        "  pos = np.empty(x.shape + (2,))\n",
        "  pos[:, :, 0] = x; pos[:, :, 1] = y\n",
        "  # Inicialmente consideramos que todas las componentes tienen la misma probabilidad\n",
        "  PIs = np.ones(k)/k # P1 to codigo aqui\n",
        "  return sigmas, PIs"
      ],
      "metadata": {
        "id": "mYCLU9M1pwXi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_sample_float(n, mi, ma):\n",
        "    return (ma - mi) * np.random.random_sample(n) + mi"
      ],
      "metadata": {
        "id": "6ae8wL26vR9b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inicializar_parametros(Dx, K):\n",
        "  # Elegir unos centros (uno para cada componente) de manera aleatoria\n",
        "  cDx = np.zeros(K*Dx.shape[1])\n",
        "  cDx.shape = (K,Dx.shape[1])\n",
        "  for d in np.arange(Dx.shape[1]):\n",
        "      cDx[:,d] = random_sample_float(K, np.min(Dx[:,d]), np.max(Dx[:,d]))\n",
        "  print('Los centros iniciales elegidos aleatoriamente son:')\n",
        "  print(cDx)\n",
        "  # calcularlas covarianzas iniciales\n",
        "  sigmas, PIs = asignar_cov_iniciales(k) # P2 tu codigo aqui\n",
        "  return  cDx, sigmas, PIs# P3 tu codigo aqui"
      ],
      "metadata": {
        "id": "2ZfN5qCtuiy2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el paso E se (re)calcula la probabilidad de que cada ejemplo pertenezca a cada una de las componentes (los valores  zik )."
      ],
      "metadata": {
        "id": "XSfD2RDOwaUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def paso_E(K, Dx,cDx, sigmas, PIs):\n",
        "    # Se calcula la probabilidad de que cada punto pertenezca a cada cl√∫ster.\n",
        "    # multivariate_normal.pdf calcula la densidad de la distribuci√≥n normal multivariada.\n",
        "    Dy_probs = np.full((Dx.shape[0], K), fill_value=np.nan, dtype=np.float64)\n",
        "    for k in np.arange(K):\n",
        "        try:\n",
        "            Dy_probs[:, k] = PIs[k] * multivariate_normal.pdf(Dx, mean=cDx[k, :], cov=sigmas[k])\n",
        "        except np.linalg.LinAlgError as e:\n",
        "            # A√±adir un peque√±o valor a la diagonal para evitar problemas de singularidad\n",
        "            sigmas[k] += np.eye(4) * 1e-6\n",
        "            Dy_probs[:, k] = PIs[k] * multivariate_normal.pdf(Dx, mean=cDx[k, :], cov=sigmas[k])\n",
        "    #Se asegura que Dy_probs se normalice para que las probabilidades sumen 1 en cada fila.\n",
        "    sum_Dy_probs = np.sum(Dy_probs, axis=1)\n",
        "    sum_Dy_probs[sum_Dy_probs == 0] = 1e-10     # Evitar la divisi√≥n por cero\n",
        "    Dy_probs =  Dy_probs / sum_Dy_probs# P4 tu codigo aqui\n",
        "    return Dy_probs"
      ],
      "metadata": {
        "id": "k-JE0cpN7zhn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el paso M se (re)calculan los par√°metros del modelo: los centros de las distribuciones normales (uno por componente,  Œºk ), las matrices de covarianzas de las normales (una por componente,  Œ£k ) y los coeficientes de importancia de las diferentes componentes ( {œÄk}Kk=1 , con  ‚àëkœÄk=1 )."
      ],
      "metadata": {
        "id": "wOAL-MHzd3gG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def paso_M(K, Dx, Dy_probs):\n",
        "    # - a: Calcular los nuevos centros de las K componentes\n",
        "    cDx = np.zeros((K, Dx.shape[1]))\n",
        "    for k in range(K):\n",
        "        cDx[k,:] = np.sum(Dy_probs[:,k,None]*Dx,axis=0)/np.sum(Dy_probs[:,k])\n",
        "    # - b: Calcular la matriz de covarianza (sigma) de las K componentes\n",
        "    sigmas = np.zeros((K, Dx.shape[1], Dx.shape[1]))\n",
        "    for k in range(K):\n",
        "        sigmas[k] = np.sum([Dy_probs[i,k]* np.dot(Dx[i,:,None]-cDx[k,:,None],\n",
        "                                                  (Dx[i,:,None]-cDx[k,:,None]).transpose())\n",
        "                          for i in np.arange(Dx.shape[0])], axis=0) / np.sum(Dy_probs[:,k])\n",
        "    # - c: Calcular los coeficientes de importancia de las diferentes componentes\n",
        "    PIs =  np.sum(Dy_probs, axis=0)/Dx.shape[0] # P5 tu codigo aqui\n",
        "    return cDx, sigmas, PIs"
      ],
      "metadata": {
        "id": "OeyQwwoEgpy-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez inicializado, el algoritmo EM ejecuta un bucle donde se repiten los pasos E y M hasta que se alcanza la convergencia.El algoritmo alcanza la convergencia cuando los par√°metros no cambian entre dos iteraciones consecutivas."
      ],
      "metadata": {
        "id": "skViDldidzRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GMM(Dx, K):\n",
        "  Dy_probs = np.zeros((Dx.shape[0], K))\n",
        "  # Flag de convergencia\n",
        "  iterando = True\n",
        "  # inicializar el modelo\n",
        "  cDx, sigmas, PIs = inicializar_parametros(Dx, k)# P6 tu codigo aqui\n",
        "  while iterando:\n",
        "    # Vector auxiliar para guardar los centros de la iteraci√≥n pasada\n",
        "    # necesarios para identificar la convergencia\n",
        "    cDx_ant = cDx.copy()\n",
        "    # PASO E:\n",
        "    Dy_probs = paso_E(k, Dx, cDx, sigmas, PIs)# P7 tu codigo aqui\n",
        "    # PASO M:\n",
        "    cDx, sigmas, PIs = paso_M(k, Dx, Dy_probs)# P8 tu codigo aqui\n",
        "    # Verificar la convergencia\n",
        "    if np.allclose(cDx, cDx_ant):\n",
        "        iterando = False\n",
        "  Dyp = np.argmax(Dy_probs,axis=1)\n",
        "  return cDx,sigmas, Dyp"
      ],
      "metadata": {
        "id": "bVAXkMZL8nJw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta funci√≥n permite vizualizar la asignacion de los puntos a los clusters y las distribuciones gausianas"
      ],
      "metadata": {
        "id": "OXY_khvfen-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.patches import Ellipse\n",
        "\n",
        "def visualizar_gmm(Dx, cDx, sigmas, Dyp, titulo=\"Resultado GMM\", padding=1):\n",
        "    K = cDx.shape[0]  # N√∫mero de clusters\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    colores = plt.cm.tab10(np.linspace(0, 1, K))\n",
        "\n",
        "    # 1. Mostrar puntos coloreados por cluster\n",
        "    for k in range(K):\n",
        "        # Puntos del cluster k\n",
        "        puntos_cluster = Dx[Dyp == k]\n",
        "        if len(puntos_cluster) > 0:\n",
        "            plt.scatter(puntos_cluster[:, 0], puntos_cluster[:, 1],\n",
        "                       color=colores[k], alpha=0.6, s=40,\n",
        "                       label=f'Cluster {k} (n={len(puntos_cluster)})')\n",
        "\n",
        "    # 2. Mostrar centros de clusters\n",
        "    plt.scatter(cDx[:, 0], cDx[:, 1],\n",
        "               color='red', marker='X', s=200,\n",
        "               edgecolors='black', linewidth=2,\n",
        "               label=f'Centros (K={K})')\n",
        "\n",
        "    # 3. Dibujar elipses de covarianza (1 desviaci√≥n est√°ndar)\n",
        "    for k in range(K):\n",
        "        # Obtener eigenvalores y eigenvectores de la matriz de covarianza\n",
        "        eigvals, eigvecs = np.linalg.eigh(sigmas[k])\n",
        "\n",
        "        # Calcular √°ngulo de rotaci√≥n\n",
        "        angulo = np.degrees(np.arctan2(eigvecs[1, 0], eigvecs[0, 0]))\n",
        "\n",
        "        # Ancho y alto de la elipse (1œÉ)\n",
        "        ancho = 2 * np.sqrt(eigvals[0])\n",
        "        alto = 2 * np.sqrt(eigvals[1])\n",
        "\n",
        "        # Crear elipse\n",
        "        elipse = Ellipse(xy=cDx[k], width=ancho, height=alto,\n",
        "                        angle=angulo, alpha=0.3,\n",
        "                        color=colores[k], linewidth=2, linestyle='--')\n",
        "\n",
        "        plt.gca().add_patch(elipse)\n",
        "\n",
        "    # 4. Calcular l√≠mites con escala igual\n",
        "    x_min, x_max = Dx[:, 0].min(), Dx[:, 0].max()\n",
        "    y_min, y_max = Dx[:, 1].min(), Dx[:, 1].max()\n",
        "\n",
        "    # Calcular rangos\n",
        "    x_range = x_max - x_min\n",
        "    y_range = y_max - y_min\n",
        "\n",
        "    # Encontrar el rango m√°ximo entre X e Y\n",
        "    max_range = max(x_range, y_range)\n",
        "\n",
        "    # Calcular centros\n",
        "    x_center = (x_min + x_max) / 2\n",
        "    y_center = (y_min + y_max) / 2\n",
        "\n",
        "    # Aplicar padding usando el mismo rango para ambos ejes\n",
        "    half_range_with_padding = (max_range * padding) / 2\n",
        "\n",
        "    # Establecer l√≠mites iguales para ambos ejes\n",
        "    x_min_final = x_center - half_range_with_padding\n",
        "    x_max_final = x_center + half_range_with_padding\n",
        "    y_min_final = y_center - half_range_with_padding\n",
        "    y_max_final = y_center + half_range_with_padding\n",
        "\n",
        "    # Crear grid para densidad usando los l√≠mites iguales\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min_final, x_max_final, 100),\n",
        "                         np.linspace(y_min_final, y_max_final, 100))\n",
        "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "    # Calcular densidad total (suma de todas las gaussianas)\n",
        "    densidad_total = np.zeros(grid.shape[0])\n",
        "\n",
        "    for k in range(K):\n",
        "        # Usar pdf de distribuci√≥n normal multivariada\n",
        "        try:\n",
        "            pdf_k = multivariate_normal.pdf(grid, mean=cDx[k], cov=sigmas[k])\n",
        "            densidad_total += pdf_k\n",
        "        except:\n",
        "            # Si hay error con la covarianza, saltar esta componente\n",
        "            continue\n",
        "\n",
        "    # Mostrar contornos si hay densidad calculada\n",
        "    if np.any(densidad_total > 0):\n",
        "        densidad_total = densidad_total.reshape(xx.shape)\n",
        "        plt.contour(xx, yy, densidad_total, levels=8, colors='black', alpha=0.5, linewidths=0.5)\n",
        "\n",
        "    # 5. Configurar gr√°fico con l√≠mites iguales\n",
        "    plt.xlim(x_min_final, x_max_final)\n",
        "    plt.ylim(y_min_final, y_max_final)\n",
        "\n",
        "    plt.xlabel('X‚ÇÅ', fontsize=12)\n",
        "    plt.ylabel('X‚ÇÇ', fontsize=12)\n",
        "    plt.title(f'{titulo} - K={K} clusters', fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Forzar mismo aspecto (relaci√≥n de aspecto 1:1)\n",
        "    plt.gca().set_aspect('equal', adjustable='box')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "PcfnRMaTzMiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ahora podemos usar GMM\n"
      ],
      "metadata": {
        "id": "UA71-QAjwLj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D =cargar_dataset(\"dataset_dos_guassianas.xlsx\")\n",
        "D = D[ np.random.choice(np.arange(D.shape[0]), D.shape[0], replace=False) ,:]\n",
        "Dx = D[:,1:3]\n",
        "Dy = D[:,3]\n",
        "fig, ax = plt.subplots(figsize=(6,4))\n",
        "ax.scatter(Dx[:,0],Dx[:,1], c=Dy)"
      ],
      "metadata": {
        "id": "fGkzu2i4vgFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = 2\n",
        "# ejecucion de GMM\n",
        "cDx, sigmas, Dyp = GMM(Dx, K)"
      ],
      "metadata": {
        "id": "GgDS-kG6v4gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizaci√≥n\n",
        "visualizar_gmm(Dx, cDx, sigmas, Dyp)"
      ],
      "metadata": {
        "id": "5zyVdJS4y7aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "Experimente con el dataset dos remolinos\n"
      ],
      "metadata": {
        "id": "lt7FUdkC9NZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D =cargar_dataset(\"dataset_dos_remolinos.xlsx\")\n",
        "D = D[ np.random.choice(np.arange(D.shape[0]), D.shape[0], replace=False) ,:]\n",
        "Dx = D[:,1:3]\n",
        "Dy = D[:,3]"
      ],
      "metadata": {
        "id": "-30z8cqd0cB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea74c67f-6981-4b39-d38b-c030ef42c1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset cargado desde URL GitHub\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = # P9 tu codigo aqui\n"
      ],
      "metadata": {
        "id": "eVQFggs7UElI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizar_gmm(Dx, cDx, sigmas, Dyp)"
      ],
      "metadata": {
        "id": "F4rGeY7n36Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimente con el dataset cuatro diferente medida"
      ],
      "metadata": {
        "id": "zsy4FTBegPDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D =cargar_dataset(\"dataset_cuatro_diferente_medida.xlsx\")\n",
        "D = D[ np.random.choice(np.arange(D.shape[0]), D.shape[0], replace=False) ,:]\n",
        "Dx = D[:,1:3]\n",
        "Dy = D[:,3]"
      ],
      "metadata": {
        "id": "AUmT4UVVMpco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "332268fe-a2aa-4db4-8200-a6ba3501b3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset cargado desde URL GitHub\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# p10. Complete el codigo\n"
      ],
      "metadata": {
        "id": "VM8EQlkeg9Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "<h2>Implementaciones en librer√≠as de Python</h2>\n",
        "\n",
        "Scikit-learn (scikit-learn) es la implementaci√≥n m√°s popular y ampliamente utilizada:"
      ],
      "metadata": {
        "id": "lvzp9oiTSzmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "k=4\n",
        "gmm = GaussianMixture(n_components=k, covariance_type='full', random_state=42)\n",
        "gmm.fit(Dx)\n",
        "labels = gmm.predict(Dx)\n",
        "probabilities = gmm.predict_proba(Dx)"
      ],
      "metadata": {
        "id": "OzrUiRu6AXf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # GRAFICAR LOS GRUPOS\n",
        "\n",
        " # P11 SU CODIGO AQUI"
      ],
      "metadata": {
        "id": "lov7zLD2go5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pruebe GMM y BGMM con los 5 dataset\n",
        "\n",
        "\n",
        "*   dataset_circulos_concentricos\n",
        "*   dataset_cuatro_diferente_densidad\n",
        "*   dataset_cuatro_separables_peque\n",
        "*   dataset_cuatro_diferente_medida\n",
        "*   dataset_inseparable\n",
        "\n"
      ],
      "metadata": {
        "id": "nbfk4cgzLSz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture import BayesianGaussianMixture, GaussianMixture\n",
        "K=4\n",
        "models = {\n",
        "     # P12 SU CODIGO AQUI\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "for (name, model), ax in zip(models.items(), axes):\n",
        "        model.fit(Dx)\n",
        "        probs = model.predict_proba(Dx) if hasattr(model, 'predict_proba') else None\n",
        "        ax.scatter(Dx[:, 0], Dx[:, 1], c=probs.argmax(axis=1) if probs is not None else 'gray')\n",
        "        ax.set_title(name + \" \" + str(K))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s4Zk-ED76MEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ ¬°TALLER FINALIZADO!\""
      ],
      "metadata": {
        "id": "iiTD50NHPUsM"
      }
    }
  ]
}