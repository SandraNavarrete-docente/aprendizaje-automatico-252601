{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üéì **Taller 4.1: Taller de Medidas de Similitud y Disimilitud**\n"
      ],
      "metadata": {
        "id": "oXCqPTRZDOp2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OBJETIVOS DEL TALLER:\n",
        "Comprender y aplicar diferentes medidas de similitud y disimilitud en conjuntos de datos, analizando su comportamiento en distintos contextos de distribuci√≥n de datos. Implementar y calcular al menos 6 medidas de distancia diferentes:\n",
        "\n",
        "* ‚úÖDistancia Euclidiana (L2)\n",
        "* ‚úÖDistancia Manhattan (L1)\n",
        "* ‚úÖDistancia Chebyshev (L‚àû)\n",
        "* ‚úÖSimilitud de Coseno\n",
        "* ‚úÖDistancia de Mahalanobis\n",
        "* ‚úÖDistancia de Jaccard\n",
        "\n",
        "Representar gr√°ficamente datasets en espacios bidimensionales\n",
        "\n",
        "* ‚úÖVisualizar centros y puntos de referencia en gr√°ficos de dispersi√≥n\n",
        "* ‚úÖInterpretar relaciones espaciales a partir de representaciones visuales"
      ],
      "metadata": {
        "id": "7upSBFL6RCda"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîß **CONFIGURACI√ìN INICIAL**"
      ],
      "metadata": {
        "id": "s2z_GPdRH4HG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [8, 8]"
      ],
      "metadata": {
        "id": "i-Xg1lLJDUak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as st\n",
        "\n",
        "def visualize_dataset(x, y, ds_center, c1, c2):\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.scatter(x, y)\n",
        "  ds_center_r = [np.mean(x), np.mean(y)]\n",
        "  print(f'Centro real del cluster: x={ds_center_r[0]:.2f}, y={ds_center_r[1]:.2f}')\n",
        "  print(f'Centro del cluster utilizado para el ejemplo: x={ds_center[0]:.2f}, y={ds_center[1]:.2f}')\n",
        "  ax.scatter(ds_center[0], ds_center[1], s=200, c='b')\n",
        "  # plot candidates\n",
        "  ax.scatter(c1[0], c1[1], s=200, c='r')\n",
        "  ax.scatter(c2[0], c2[1], s=200, c='g', marker='v')\n",
        "  deltaX = (max(x) - min(x))/10\n",
        "  deltaY = (max(y) - min(y))/10\n",
        "  xmin = min(x) - deltaX\n",
        "  xmax = max(x) + deltaX\n",
        "  ymin = min(y) - deltaY\n",
        "  ymax = max(y) + deltaY\n",
        "  # Create meshgrid\n",
        "  xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
        "  positions = np.vstack([xx.ravel(), yy.ravel()])\n",
        "  values = np.vstack([x, y])\n",
        "  kernel = st.gaussian_kde(values)\n",
        "  f = np.reshape(kernel(positions).T, xx.shape)\n",
        "  # create gaussian contour lines\n",
        "  cfset = ax.contourf(xx, yy, f, cmap='coolwarm', alpha=0.2)\n",
        "  ax.imshow(np.rot90(f), cmap='coolwarm', extent=[xmin, xmax, ymin, ymax], alpha=0.2)\n",
        "  # write labels\n",
        "  cset = ax.contour(xx, yy, f, colors='k', linestyles='dotted')\n",
        "  ax.clabel(cset, inline=1, fontsize=10)\n",
        "  ax.set_xlabel('X')\n",
        "  ax.set_ylabel('Y')\n",
        "  plt.title('Kernel Gaussiano 2D')"
      ],
      "metadata": {
        "id": "DfxqlBHCnEXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_scatter(x, y, ds_center, c1, c2):\n",
        "  ds_center_real= [np.mean(x), np.mean(y)]\n",
        "  plt.figure(figsize=(8, 6))  # Tama√±o del gr√°fico\n",
        "  plt.scatter(x, y, color='blue', alpha=0.6, label='Puntos de datos')\n",
        "  plt.scatter(ds_center[0], ds_center[1], color='red', marker='X', s=100, label='Centro [2, 2]')\n",
        "  plt.scatter(ds_center_real[0], ds_center_real[1], color='y', marker='X', s=100, label='Centro Real')\n",
        "  plt.scatter(c1[0], c1[1], s=200, c='red', label='Candidato 1 (rojo)')\n",
        "  plt.scatter(c2[0], c2[1], s=200, c='green', marker='v', label='Candidato 2 (verde)')\n",
        "  plt.xlabel('Variable 1 (data_var_1)')\n",
        "  plt.ylabel('Variable 2 (data_var_2)')\n",
        "  plt.title('Dataset 2D con Distribuci√≥n Normal alrededor de [2, 2]')\n",
        "  plt.grid(True, linestyle='--', alpha=0.5)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "m1tM1uVanGvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìÅ **CREAR LOS DATASETS Y GRAFIQUE SUS DISTRIBUCIONES**"
      ],
      "metadata": {
        "id": "jbgcqhpSH9_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un dataset artificial alrededor de un punto\n",
        "def cargar_datasetDistNormal(n_data_points = 50, ds_center = np.array([2, 2])):\n",
        "    # para hacer los experimentos reproducibles\n",
        "    np.random.seed(42)\n",
        "    # generamos los puntox en 2D con funcion normal, al rededor del centro\n",
        "    data_var_1 = np.random.randn(n_data_points) + ds_center[0]\n",
        "    data_var_2 = np.random.randn(n_data_points) + ds_center[1]\n",
        "    return data_var_1, data_var_2"
      ],
      "metadata": {
        "id": "ejuHthB-Hydr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un dataset artificial alrededor de un punto con una relacion lineal de dependencia entre las variables\n",
        "def cargar_datasetRelacionLineal(factor=np.array([1, 1]), n_data_points = 50, ds_center = np.array([2, 2])):\n",
        "    # para hacer los experimentos reproducibles\n",
        "    np.random.seed(42)\n",
        "    # generar los datos con una relacion lineal\n",
        "    data_var_1b = factor[0] * np.random.randn(n_data_points) + ds_center[0]\n",
        "    data_var_2b = data_var_1b + factor[1] * np.random.randn(n_data_points)\n",
        "    return data_var_1b, data_var_2b"
      ],
      "metadata": {
        "id": "ifCikvK2noBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un dataset artificial alrededor de un punto con una relacion cuadratica de dependencia entre las variables\n",
        "def cargar_datasetRelacionCuadratica(coeficientes=np.array([1, 0, 0]),\n",
        "                                     n_data_points=50,\n",
        "                                     rango_x=(-5, 5)):\n",
        "    #coeficientes : array de 3 elementos [a, b, c]\n",
        "    #    Coeficientes de la ecuaci√≥n cuadr√°tica: y = a*x¬≤ + b*x + c\n",
        "    # Para hacer los experimentos reproducibles\n",
        "    np.random.seed(42)\n",
        "    # Extraer coeficientes\n",
        "    a, b, c = coeficientes\n",
        "    # Generar valores x uniformemente distribuidos\n",
        "    x = np.random.uniform(rango_x[0], rango_x[1], n_data_points)\n",
        "    # Aplicar la transformaci√≥n cuadr√°tica\n",
        "    y_ideal = a * x**2 + b * x + c\n",
        "    # A√±adir ruido aleatorio (proporcional al rango de y)\n",
        "    rango_y = np.max(y_ideal) - np.min(y_ideal)\n",
        "    ruido = 0.1 * rango_y * np.random.randn(n_data_points)\n",
        "    y = y_ideal + ruido\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "ISllNudK28Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar dataset\n",
        "ds_center = np.array([2, 2])\n",
        "dx, dy =cargar_datasetDistNormal(50, ds_center)\n",
        "# establecemos nuestros dos puntos candidatos de prueba\n",
        "c1 = np.array([ds_center[0] - 1, 3])\n",
        "c2 = np.array([ds_center[1] + 1, 3])\n",
        "visualize_scatter(dx, dy, ds_center, c1, c2)\n",
        "visualize_dataset(dx, dy, ds_center, c1, c2)"
      ],
      "metadata": {
        "id": "lYEdHd7ULeYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéØ **EJ 1:GRAFIQUE LAS DISTRIBUCIONES DE LOS DATASETS**"
      ],
      "metadata": {
        "id": "CuG_2IWbtLe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO 1.1 crear y vizualizar el dataset con relacion lineal y con relacion cuadratica\n",
        "dxr, dyr = # Complete\n",
        "\n",
        "dx2, dy2 = # Complete"
      ],
      "metadata": {
        "id": "mYCLU9M1pwXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset grande\n",
        "dxGrande, dyGrande =cargar_datasetRelacionLineal([20,10], 1000, [50,100])"
      ],
      "metadata": {
        "id": "GgDS-kG6v4gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéØ **EJ 2: IDENTIFIQUE QUE TAN DEPENDIENTES SON LOS DATASETS**"
      ],
      "metadata": {
        "id": "q3aJRGrp5-65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO 2.1 : Use la covarianza para identificar que tan dependiente es la relacion que existe entre los registros de los datasets {dx,dy}, {dxr, dyr}, {dx2, dy2} y {dxGrande, dyGrande}\n",
        "# su codigo aqui np.cov\n",
        "print(f'Covarianza dataset con distribuci√≥n normal:\\n')\n",
        "\n",
        "print(f'Covarianza dataset con relaci√≥n lineal :\\n')\n",
        "\n",
        "\n",
        "print(f'Covarianza dataset con relaci√≥n lineal Grande:\\n')\n",
        "\n",
        "\n",
        "print(f'Covarianza dataset con relaci√≥n cuadratica:\\n')\n"
      ],
      "metadata": {
        "id": "yijxPuqxMdSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìà **RESULTADOS:**\n",
        "**Conteste las siguientes preguntas**\n",
        "\n",
        "¬øQu√© dataset tiene una mayor dependencia lineal entre sus dos variables?\n",
        "\n",
        "¬øCual es el problema que tiene la covarianza?"
      ],
      "metadata": {
        "id": "aB341pVzQVrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO 2.2: Use el coeficiente de correlaci√≥n de Pearson para identificar que tan dependiente es la relacion que existe entre los registros de los datasets {dx,dy}, {dxr, dyr} y {dxGrande, dyGrande}\n",
        "# su codigo aqui np.corrcoef"
      ],
      "metadata": {
        "id": "hOBc7FnWNt7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìà **RESULTADOS:**\n",
        "**Conteste las siguientes preguntas**\n",
        "\n",
        "¬øQu√© dataset tiene una mayor dependencia lineal entre sus dos variables?\n",
        "\n",
        "¬øQue medida es mas facil de interpretar para identificar la dependencia entre dos variables de un dataset?"
      ],
      "metadata": {
        "id": "Q9E46I0CzKD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéØ **EJ 3: CREE LAS FUNCIONES DE LAS MEDIDAS DE DISIMILITUD**"
      ],
      "metadata": {
        "id": "v1LecSo9LvL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  TODO 3.1 completar el codigo de las funciones de las siguientes medidas de disimilitud:\n",
        "#  Distancia Euclidiana, Distancia Manhattan, Distancia Chebyshev, Similitud de Coseno, Mahalanobis y Jaccard\n",
        "#  En scipy.spatial.distance tenemos disponibles las distancias minkowski, mahalanobis, jaccard, hamming, euclidean, cosine, entre otras.\n",
        "#  En numpy tenemos la norma p =  np.linalg.norm"
      ],
      "metadata": {
        "id": "Mbvp880xsXnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distancia_euclidiana(p1, p2):\n",
        "   dist = np.linalg.norm(p2 - p1, ord= 1)\n",
        "   print(f'Distancia euclidiana del punto {p1} al punto {p2} = {dist}')\n",
        "   return dist"
      ],
      "metadata": {
        "id": "UxOp1ucrLpkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distancia_manhattan(p1, p2):\n",
        "   dist =  # ‚Üê COMPLETAR\n",
        "   print(f'Distancia manhattan del punto {p1} al punto {p2} = {dist}')\n",
        "   return dist"
      ],
      "metadata": {
        "id": "mZXzFmjPr-80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚Üê COMPLETAR Chebyshev, Similitud de Coseno, Mahalanobis y Jaccard"
      ],
      "metadata": {
        "id": "eWuQEPHLssP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecutar funciones\n",
        "print(\"üîç calculando las distancias de los puntos candidatos al centro\")\n",
        "print('Distancias primer dataset:\\n')\n",
        "ds_center =  # ‚Üê COMPLETAR, calcule el centro del primer dataset\n",
        "dist_euc1 = distancia_euclidiana(c1, ds_center)\n",
        "dist_euc2 = distancia_euclidiana(c2, ds_center)\n",
        " # ‚Üê COMPLETAR, el resto de distancias\n",
        "print('Distancias segundo dataset:\\n')\n",
        "# ‚Üê COMPLETAR, calcule el centro del segundo dataset\n",
        "\n",
        "# ‚Üê COMPLETAR para el resto de datasets"
      ],
      "metadata": {
        "id": "T3djvOKAMKLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìà **RESULTADOS:**\n",
        "**Conteste las siguientes preguntas**\n",
        "\n",
        "¬øQu√© medidas de disimilitud son de un punto a otro punto?\n",
        "¬øQu√© medidas de disimilitud son de un punto a una distribuci√≥n?\n",
        "\n",
        "¬øLa distancia de Mahalanobis es capaz de tener en cuenta la distribuci√≥n real de los datos?"
      ],
      "metadata": {
        "id": "OC9KQoo2fgiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîÑ **EJ 4: MATRIZ DE DISTANCIAS**\n",
        "\n",
        "Cree un metodo que sea capaz de calcular la matriz de distancias de todos los puntos de un dataset, recive como parametros la medida de disimilitud y en algunos casos la matriz de covarianza"
      ],
      "metadata": {
        "id": "loS7_awKN08W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools as it\n",
        "#  TODO 4.1 completar el codigo\n",
        "def matriz_distancias(X, distancia, mC=None):\n",
        "    n_samples = X.shape[0]\n",
        "    mD = np.zeros((n_samples, n_samples))\n",
        "    for pair in it.product(np.arange(n_samples), repeat=2):\n",
        "        if mC is not None:\n",
        "            mD[pair] = # Complete\n",
        "        else:\n",
        "            mD[pair] =  # Complete\n",
        "    return mD"
      ],
      "metadata": {
        "id": "BcrbLsQVN6k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # ‚Üê COMPLETAR calcule y grafique la matriz de distancias para todos los datasets y use la medida de disimilitud euclidiana y mahalanobis\n",
        "# calculamos primero la matriz de covarianzas\n",
        "mC = np.cov(,)\n",
        "Ma_mahalanobis = matriz_distancias(X, distancia_mahalanobis, mC)\n",
        "print('Matriz distancias:\\n', Ma_mahalanobis)\n"
      ],
      "metadata": {
        "id": "EiUYi7q0OJeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(Ma_euclidea, cmap='jet')\n",
        "ax[0].set_title('Euclidea')\n",
        "ax[1].imshow(Ma_mahalanobis, cmap='jet')\n",
        "ax[1].set_title('Mahalanobis')"
      ],
      "metadata": {
        "id": "L2SYxqJfhkhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hasta ahora hemos visto todo disimilitudes (distancias). ¬øY si quisi√©ramos una medida de similitud?\n",
        "def matriz_similitud(X, distancia, mC=None):\n",
        "    if mC is not None:\n",
        "        mD = matriz_distancias(X, distancia, mC)\n",
        "    else:\n",
        "        mD = matriz_distancias(X, distancia)\n",
        "    # complete\n",
        "    return ## 4.2. Tu c√≥digo aqu√≠ ##"
      ],
      "metadata": {
        "id": "5rKwoObAhy2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete 4.3 Grafique la matriz de similitud"
      ],
      "metadata": {
        "id": "J7DT-82ZiEvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ **RESULTADOS:**\n",
        "¬øCual grafico es mas facil de interpretar: el de una medida de disimilitud o de similitud?\n",
        "\n"
      ],
      "metadata": {
        "id": "p5MjcKzUdkjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ ¬°TALLER FINALIZADO!\""
      ],
      "metadata": {
        "id": "iiTD50NHPUsM"
      }
    }
  ]
}